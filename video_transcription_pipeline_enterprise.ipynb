{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "631a0c19",
   "metadata": {},
   "source": [
    "# Video Transcription and Subtitle Embedding Pipeline (Production-Grade)\n",
    "\n",
    "This notebook extends the refactored version with:\n",
    "- Hash-based audio fingerprints (idempotent processing)\n",
    "- CPU/GPU-aware parallel transcription\n",
    "- Structured JSON logs for post-run audit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc60fbc",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a02c061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.audio_transcribe import transcribe_audio\n",
    "from src.embed_caption import embed_subtitles\n",
    "from media_tool.media_tool import run\n",
    "import os, json, hashlib, time\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1e2cc2",
   "metadata": {},
   "source": [
    "## 2. Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "242fc600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Working directory: C:\\Users\\ingca\\OneDrive\\Documents\\python\\test_ac\n"
     ]
    }
   ],
   "source": [
    "VIDEO_DIR = Path(r\"/mnt/c/Users/ingca/Videos/Diavoli S01 (2020) 1080p WEB-DL H264 iTA ENG AC3 - iDN_CreW\")\n",
    "WORKDIR = Path.cwd()\n",
    "LANGS = [\"eng\"]\n",
    "DEFAULT_LANG = \"eng\"\n",
    "WHISPER_MODEL_SIZE = \"medium\"\n",
    "MAX_WORKERS_CPU = os.cpu_count() // 2\n",
    "MAX_WORKERS_GPU = 1\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "WORKDIR = Path.cwd().resolve()\n",
    "WORKDIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"→ Working directory: {WORKDIR}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed691abf",
   "metadata": {},
   "source": [
    "## 3. Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb356706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Working directory: C:\\Users\\ingca\\OneDrive\\Documents\\python\\test_ac\n",
      "→ WORKDIR type: <class 'pathlib.WindowsPath'>\n",
      "WORKDIR = C:\\Users\\ingca\\OneDrive\\Documents\\python\\test_ac\n",
      "Exists  = True\n",
      "Is dir  = True\n",
      "Is file = False\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] Impossibile trovare il file specificato: 'c:\\\\Users\\\\ingca\\\\OneDrive\\\\Documents\\\\python\\\\test_ac\\\\fingerprints'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIs dir  =\u001b[39m\u001b[38;5;124m\"\u001b[39m, WORKDIR\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIs file =\u001b[39m\u001b[38;5;124m\"\u001b[39m, WORKDIR\u001b[38;5;241m.\u001b[39mis_file())\n\u001b[1;32m---> 10\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetcwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfingerprints\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m p \u001b[38;5;241m=\u001b[39m WORKDIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfingerprints\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     14\u001b[0m WORKDIR \u001b[38;5;241m=\u001b[39m Path(WORKDIR)\u001b[38;5;241m.\u001b[39mresolve()\n",
      "File \u001b[1;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Impossibile trovare il file specificato: 'c:\\\\Users\\\\ingca\\\\OneDrive\\\\Documents\\\\python\\\\test_ac\\\\fingerprints'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "WORKDIR = Path(WORKDIR)\n",
    "print(f\"→ Working directory: {WORKDIR}\")\n",
    "print(f\"→ WORKDIR type: {type(WORKDIR)}\")\n",
    "print(\"WORKDIR =\", WORKDIR)\n",
    "print(\"Exists  =\", WORKDIR.exists())\n",
    "print(\"Is dir  =\", WORKDIR.is_dir())\n",
    "print(\"Is file =\", WORKDIR.is_file())\n",
    "\n",
    "\n",
    "p = WORKDIR / \"fingerprints\"\n",
    "WORKDIR = Path(WORKDIR).resolve()\n",
    "WORKDIR.mkdir(parents=True, exist_ok=True)\n",
    "p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "print(p.exists(), p.is_dir(), p.is_file())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8c0fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DIRS = {\n",
    "    \"subbed\": WORKDIR / \"subbed\",\n",
    "    \"srt\": WORKDIR / \"srt\",\n",
    "    \"input_files\": WORKDIR / \"input_files\",\n",
    "    \"fingerprints\": WORKDIR / \"fingerprints\",\n",
    "    \"logs\": WORKDIR / \"logs\",\n",
    "}\n",
    "\n",
    "for d in DIRS.values():\n",
    "    d.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b63330",
   "metadata": {},
   "source": [
    "## 4. Structured Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600012dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FILE = DIRS[\"logs\"] / \"run_log.jsonl\"\n",
    "\n",
    "def log_event(event: dict):\n",
    "    event[\"timestamp\"] = time.time()\n",
    "    with open(LOG_FILE, \"a\") as f:\n",
    "        f.write(json.dumps(event) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4897043",
   "metadata": {},
   "source": [
    "## 5. Audio Fingerprinting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55ddce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fingerprint_file(path: Path) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with open(path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(8192), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72008d5a",
   "metadata": {},
   "source": [
    "## 6. Whisper Model (GPU aware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e863f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = whisper.load_model(WHISPER_MODEL_SIZE, device=device)\n",
    "MAX_WORKERS = MAX_WORKERS_GPU if device == \"cuda\" else MAX_WORKERS_CPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d87d35",
   "metadata": {},
   "source": [
    "## 7. Episode Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240348b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = sorted([p for p in VIDEO_DIR.iterdir() if p.suffix == \".mkv\"])\n",
    "ep_to_exclude = ['S01E01', 'S01E02', 'S01E03', 'S01E04', 'S01E05', 'S01E06', 'S01E07']\n",
    "episodes = [ep for ep in episodes if not any(bad in ep for bad in ep_to_exclude)]\n",
    "print(f\"→ Episodes to process: {[ep.name for ep in episodes]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ad6fbe",
   "metadata": {},
   "source": [
    "## 8. Episode Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c27dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_episode(video_path: Path):\n",
    "    episode = video_path.stem\n",
    "    try:\n",
    "        run(\n",
    "            input_path=str(video_path),\n",
    "            output_dir=str(DIRS[\"input_files\"]),\n",
    "            languages=LANGS,\n",
    "            default_language=DEFAULT_LANG,\n",
    "        )\n",
    "\n",
    "        audio_dir = DIRS[\"input_files\"] / episode\n",
    "        audio_file = next(f for f in audio_dir.iterdir() if f.suffix == \".mka\" and DEFAULT_LANG in f.name)\n",
    "\n",
    "        fp = fingerprint_file(audio_file)\n",
    "        fp_file = DIRS[\"fingerprints\"] / f\"{fp}.json\"\n",
    "\n",
    "        srt_path = DIRS[\"srt\"] / f\"{episode}_subtitles.srt\"\n",
    "\n",
    "        if not fp_file.exists():\n",
    "            log_event({\"episode\": episode, \"stage\": \"transcription_start\"})\n",
    "            srt_path = transcribe_audio(\n",
    "                audio_file=str(audio_file),\n",
    "                output_dir=str(DIRS[\"srt\"]),\n",
    "                output_format=\"srt\",\n",
    "                model=model,\n",
    "            )\n",
    "            fp_file.write_text(json.dumps({\"episode\": episode, \"audio\": str(audio_file)}))\n",
    "            log_event({\"episode\": episode, \"stage\": \"transcription_done\"})\n",
    "        else:\n",
    "            log_event({\"episode\": episode, \"stage\": \"transcription_skipped\"})\n",
    "\n",
    "        embed_subtitles(\n",
    "            input_mkv=str(video_path),\n",
    "            subtitle_files=[{\"file\": str(srt_path), \"language\": DEFAULT_LANG}],\n",
    "            output_mkv=str(DIRS[\"subbed\"] / f\"{episode}_with_subs.mkv\"),\n",
    "        )\n",
    "\n",
    "        log_event({\"episode\": episode, \"stage\": \"completed\"})\n",
    "    except Exception as e:\n",
    "        log_event({\"episode\": episode, \"stage\": \"error\", \"error\": str(e)})\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2878c4b",
   "metadata": {},
   "source": [
    "## 9. Parallel Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8213268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futures = [executor.submit(process_episode, ep) for ep in episodes]\n",
    "    for f in tqdm(as_completed(futures), total=len(futures), desc=\"Episodes\"):\n",
    "        f.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956abf32",
   "metadata": {},
   "source": [
    "## 10. Auditability\n",
    "\n",
    "- Fingerprints guarantee idempotency across runs\n",
    "- JSONL logs allow replay, filtering, and forensic inspection\n",
    "- Parallelism adapts automatically to CPU/GPU availability\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
